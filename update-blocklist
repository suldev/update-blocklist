#!/bin/python3

import os, glob
import requests
from datetime import datetime as dt
import argparse
import shutil
import subprocess as proc

# Application static configuration
line_prefix = 'local=/'
line_postfix= '/\n'
file_search_key = '*.txt'
installation_path = '/etc/dnsmasq.d/'

def warmup(parser, args):
    # Check whitelist
    if args.w is not None and args.W is not None:
        parser.print_help()
        print('EE Attributes whitelist and W cannot be used in the same context')
        quit()
    block_lists = []
    try:
        contents = []
        with open(args.blocklisturls, 'r') as file:
            contents = file.readlines()
        for content in contents:
            if(content[0] != '#'): block_lists.append(content.rstrip())
    except FileNotFoundError:
        print('EE Url file ' + args.blocklisturls + ' is missing')
        quit()
    if len(block_lists) == 0:
        print('EE Blocklist was empty. You must provide some external blocklist file.')
        quit()
    whitelist_urls = []
    if args.w is not None:
        temp = args.w.readlines()
        for t in temp:
            if(t[0] != '#'): whitelist_urls.append(t.rstrip())
    omit = args.W is not None
    if args.W is not None:
        temp = args.W.readlines()
        for t in temp:
            whitelist_urls.append(t.rstrip())
    temp_path = args.path
    out_path = os.path.join(temp_path, args.output)
    time_format = args.T
    if os.path.exists(temp_path):
        print('WW Temporary path already exists')
    else:
        os.mkdir(temp_path)
    return out_path, temp_path, time_format, whitelist_urls, set(block_lists), omit

def pull_blocklists(blocklist_urls, save_path):
    for blocklist_url in blocklist_urls:
        try:
            response = requests.get(blocklist_url)

            response.raise_for_status()

            save_file = os.path.join(save_path, blocklist_url[blocklist_url.rfind('/') + 1:])

            with open(save_file, 'wb') as f:
                f.write(response.content)

        except requests.exceptions.HTTPError as errh:
            print(f"HTTP Error: {errh}")
        except requests.exceptions.ConnectionError as errc:
            print(f"Error Connecting: {errc}")
        except requests.exceptions.Timeout as errt:
            print(f"Timeout Error: {errt}")
        except requests.exceptions.RequestException as err:
            print(f"Other Error: {err}")

def distill_blocklists(file_collection, whitelist_urls, omit):
    all_lines = []
    clean_lines = []
    all_urls = []
    files = glob.glob(file_collection)
    # Merge files
    for file in files:
        with open(file,'r') as file_in:
            all_lines += file_in.readlines()
    # Check lines
    clean_lines = [s for s in all_lines if s.startswith(line_prefix)]
    clean_lines = [s for s in clean_lines if s.endswith(line_postfix)]
    # Remove pre and post fixes
    for line in all_lines:
        all_urls.append(line[len(line_prefix):-len(line_postfix)])
    set_urls = set(all_urls)
    sorted_urls = sorted(set_urls, key=str.lower)
    distilled_lines = []
    if len(whitelist_urls) > 0:
        for sorted_url in sorted_urls:
            if sorted_url in whitelist_urls:
                if not omit:
                    distilled_lines.append("#" + line_prefix + sorted_url + line_postfix)
            else:
                distilled_lines.append(line_prefix + sorted_url + line_postfix)
    else:
        for sorted_url in sorted_urls:
            distilled_lines.append(line_prefix + sorted_url + line_postfix)
    return distilled_lines, len(all_lines), len(clean_lines), len(sorted_urls), len(distilled_lines)

def write_blocklist(blocklist, path, time_format):
    with open(path, 'w') as file:
        file.write("# suldev custom blocklist v0.1\n")
        file.write(f"# Published: {dt.now().strftime(time_format)}\n")
        file.write(f"# Unique Entries: {len(blocklist)}\n")
        for line in blocklist:
            file.writelines(f"{line}")

def main():
    # Handle arguments
    parser = argparse.ArgumentParser(
        prog='Update Blocklist',
        description='Combines multiple blocklist files into a single dnsmasq configuration file. This program is limited to dnsmasq blocklists since 2.86'
    )
    parser.add_argument('blocklisturls', help='Required. New-line delimited list of urls. Use # for comments')
    parser.add_argument('path', help='Required. The working and output path')
    parser.add_argument('-i', '--install', default=False, action='store_true', help='Install the configuration file and restart dnsmasq. Must be run as root.')
    parser.add_argument('-o', '--output', default='blocklist.conf', help='Output file name. Defaults to blocklist.conf')
    parser.add_argument('-T', default='%Y-%m-%d %H:%M:%S', metavar='FORMAT', help='Set the time stamp formatting using python standard strftime format')
    parser.add_argument('-l', '--local', default=False, action='store_true', help='Merge local blocklists')
    parser.add_argument('-p', '--persist', default=False, action='store_true', help='Do not clean up the temporary files')

    wl_group = parser.add_argument_group('Whitelist', 'Provide a newline-separated list of urls to whitelist')
    exclusive_group = wl_group.add_mutually_exclusive_group()
    exclusive_group.add_argument('-w', default=None, type=argparse.FileType('r'), metavar='FILE', help='Matching lines will be commented out in the output file')
    exclusive_group.add_argument('-W', default=None, type=argparse.FileType('r'), metavar='FILE', help='Matching lines will be omitted from the output file')

    args = parser.parse_args()

    if args.install:
        import errno
        try:
            with open(os.path.join(installation_path, args.output), 'w'):
                i = 0
        except OSError as e:
            if e.errno == 2:
                print(f'FF Installation path {installation_path} does not exist.')
            if e.errno == 13:
                print('FF Installation requires sudo.')
            quit()

    print(":: Warming up")
    out_path, temp_path, time_format, whitelist_urls, blocklist_urls, omit = warmup(parser, args)

    if args.local == False:
        print(":: Pulling blocklists")
        pull_blocklists(blocklist_urls, temp_path)

    print(":: Distilling blocklists")
    distill_lines, all_lines_len, clean_lines_len, unique_urls_len, distill_lines_len = distill_blocklists(os.path.join(temp_path, file_search_key), whitelist_urls, omit)
    print(f"   Total lines: {all_lines_len}")
    print(f"   Valid lines: {clean_lines_len}")
    print(f"   Unique lines: {unique_urls_len}")
    print(f"   Blacklist lines: {distill_lines_len}")
    print(f"   Removed lines:  {all_lines_len - distill_lines_len}")
    
    print(":: Cleaning up")
    write_blocklist(distill_lines, out_path, time_format)
    if args.install:
        test_proc = proc.run(['dnsmasq', f'--conf-file={out_path}', '--test'], capture_output=True, check=True)
        if(test_proc.returncode != 0):
            quit()
        quit()
        shutil.move(out_path, installation_path)
        proc.run(['systemctl','restart','dnsmasq'])
    if not args.persist:
        shutil.rmtree(temp_path)

if __name__ == '__main__':
    main()
